import numpy as np
import pandas as pd
from pathos.multiprocessing import ProcessingPool as Pool
import os
from time import perf_counter
from bispectrum_real_data_analysis.scripts.utils import seconds_to_formatted_time


def fft(x: np.ndarray | list, fs: float) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
    """This method calculates the FFT of the signal x, with the sampling frequency fs."""
    N = len(x)
    FFT = np.fft.fft(x)
    P2 = np.abs(FFT/N)
    intensity = P2[0:N//2]
    intensity[1:-1] = 2*intensity[1:-1]
    frequency = fs*np.arange(0,N//2)/N
    angle = np.angle(FFT)
    angle = angle[0:N//2]
    return frequency, intensity, angle

def load_data():
    """This method loads the data from the csv files generated by the script run_and_process_data.m.
    For each animal, the data must be generated, and then, the files must be copied to the data folder.
    Then, adjust the files names in the code below.

    Returns:
        data (pd.DataFrame): Dataframe with the data from the csv file.
        events_index (pd.DataFrame): Dataframe with the data from the csv file.
        events_index_timestamp (pd.DataFrame): Dataframe with the data from the csv file.
        events_behavior_TS_LFP_index (pd.DataFrame): Dataframe with the data from the csv file.
        events_behavior_TS_LFPsec (pd.DataFrame): Dataframe with the data from the csv file.
        BASE_PATH (str): Path to the data folder.
    """
    BASE_PATH = os.getcwd() + "/bispectrum_real_data_analysis/data"
    data = pd.read_csv(f"{BASE_PATH}/data_matrix.csv", delimiter=',', encoding="utf8")
    events_index = pd.read_csv(f"{BASE_PATH}/events_index.csv", delimiter=',', encoding="utf8")
    events_index_data_array = np.full((len(data),), None)

    for start, end, event_idx in zip(events_index.start, events_index.end, np.arange(1, len(events_index))):
        events_index_data_array[start:end] = event_idx
        
    data = data.assign(events_index=events_index_data_array)
    events_index_timestamp = pd.read_csv(f"{BASE_PATH}/events_index_timestamp.csv", delimiter=',', encoding="utf8")
    events_behavior_TS_LFP_index = pd.read_csv(f"{BASE_PATH}/events_behavior_TS_LFPindex.csv", delimiter=',', encoding="utf8")

    # Inserting the events behavior data in the dataframe as a column

    events_behavior_TS_LFP_index_array = np.full((len(data),), None)

    for start, end, event_idx in zip(events_behavior_TS_LFP_index.start, events_behavior_TS_LFP_index.end, np.arange(1, len(events_behavior_TS_LFP_index))):
        events_behavior_TS_LFP_index_array[start:end] = event_idx
        
    data = data.assign(events_behavior_TS_LFP_index=events_behavior_TS_LFP_index_array)

    events_behavior_TS_LFPsec = pd.read_csv(f"{BASE_PATH}/events_behavior_TS_LFPsec.csv", delimiter=',', encoding="utf8")

    return data, events_index, events_index_timestamp, events_behavior_TS_LFP_index, events_behavior_TS_LFPsec, BASE_PATH

def select_event_window(
    df: pd.DataFrame, 
    event_number: int, 
    samples_before: int = 0, 
    samples_after: int = 0
) -> pd.DataFrame:
  """
  Method to extract the slice of the dataframe which contais the event, with some data before and after, 
  given number of samples to add to the begin and end, respectively.
  """
  
  window_index = np.argwhere(data.events_index.to_numpy() == event_number).flatten()
  begin_index = window_index[0] - samples_before
  end_index = window_index[-1] + samples_after
  return df[begin_index:end_index]


def decimate(data, desired_frequency_sampling):
    backup_data = data.copy()
    time = backup_data.Time.to_numpy()
    TimeSampling = round(np.mean(time[1:] - time[:-1]), 6)
    FrequencySampling = 1.0/TimeSampling
    print(f"The time sampling is {TimeSampling} seconds and the frequency is "
        f"{FrequencySampling/float(1000**(FrequencySampling<=1000))} {'k'*bool(FrequencySampling>=1000)}Hz")

    newTimeSampling = 1.0/desired_frequency_sampling
    decimation_rate = np.ceil(newTimeSampling/TimeSampling).astype(int)
    print(f"The data will be decimated by the rate 1:{decimation_rate}")

    data = data[::decimation_rate]

    TimeSampling = newTimeSampling
    
    FrequencySampling = 1.0/TimeSampling
    print(f"The new time sampling is {np.round(TimeSampling, 5)} s and the new frequency is "
    f"{FrequencySampling/float(1000**(FrequencySampling>=1000))} {'k'*bool(FrequencySampling>=1000)}Hz")
    
    return data, TimeSampling, FrequencySampling, backup_data


def process_fft(
    column: list[str], 
    df: pd.DataFrame, 
    FrequencySampling: float
) -> dict:
    """ Method to process the FFT for a given column

    Args:
        column (list[str]): column name
        df (pd.DataFrame): dataframe with the data
        FrequencySampling (dict): Sampling frequency

    Returns:
        dict: dict with the column name and the result of the FFT
    """
    signal = df[column]
     
    return {
        "column": column, 
        "result": fft(x=signal, fs=FrequencySampling)
    }


if __name__ == "__main__":


    # From here, the script will run the same for all configurations
    data, events_index, events_index_timestamp, events_behavior_TS_LFP_index, events_behavior_TS_LFPsec, BASE_PATH = load_data()

    samples_before = 0
    samples_after = 0
    event_number = 1

    event_data = select_event_window(
        df=data,
        event_number=event_number,
        samples_before=samples_before,
        samples_after=samples_after
    )

    desired_frequency_sampling = 200

    data, TimeSampling, FrequencySampling, backup_data = decimate(event_data, desired_frequency_sampling=desired_frequency_sampling)

    time = event_data.Time.to_numpy()

    FFT_df = pd.DataFrame()
    phases_df = pd.DataFrame()

    print("Processing the FFT... This may take a while...\n")
    start_time = perf_counter()

    # Process the tdbs for each channel, in parallel
    with Pool() as pool:
        channels_columns = event_data.columns[2:18]

        for result in pool.map(
            lambda column: process_fft(
                column, 
                event_data, 
                FrequencySampling
            ), 
            channels_columns
        ):
            column = result["column"]
            signal = event_data[column].to_numpy()
            frequency_array, intensity_fft, angle_fft = result["result"]

            if "frequency" not in FFT_df.columns:
                FFT_df = FFT_df.assign(frequency=frequency_array)

            FFT_df = FFT_df.assign(**{f"FFT_{column}": intensity_fft})
            phases_df = phases_df.assign(**{f"phase_{column}": angle_fft})



    FFT_df = pd.concat([FFT_df, phases_df], axis=1)

    FFT_df.to_csv(f'{BASE_PATH}/fft.csv', index=False)

    end_time = perf_counter()

    print(f"Done. Elapsed time: {seconds_to_formatted_time(end_time - start_time)}")

    